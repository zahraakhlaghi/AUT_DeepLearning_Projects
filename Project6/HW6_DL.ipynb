{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bJx34QPCpcJa",
    "outputId": "26c774f0-67d7-4215-e8e5-ccc08c74c82d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rPXL63o_hnWe",
    "outputId": "7011e281-79af-4920-bf89-8a2b5f58f301"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
     ]
    }
   ],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DBdCxunRmJ4G"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxNNzUuvMtJC"
   },
   "source": [
    "\n",
    "## model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Up7Gxg8lKqTu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "def l2normalize(v, eps=1e-12):\n",
    "    return v / (v.norm() + eps)\n",
    "\n",
    "\n",
    "class SpectralNorm(nn.Module):\n",
    "    def __init__(self, module, name='weight', power_iterations=1):\n",
    "        super(SpectralNorm, self).__init__()\n",
    "        self.module = module\n",
    "        self.name = name\n",
    "        self.power_iterations = power_iterations\n",
    "        if not self._made_params():\n",
    "            self._make_params()\n",
    "\n",
    "    def _update_u_v(self):\n",
    "        u = getattr(self.module, self.name + \"_u\")\n",
    "        v = getattr(self.module, self.name + \"_v\")\n",
    "        w = getattr(self.module, self.name + \"_bar\")\n",
    "\n",
    "        height = w.data.shape[0]\n",
    "        for _ in range(self.power_iterations):\n",
    "            v.data = l2normalize(torch.mv(torch.t(w.view(height,-1).data), u.data))\n",
    "            u.data = l2normalize(torch.mv(w.view(height,-1).data, v.data))\n",
    "\n",
    "        # sigma = torch.dot(u.data, torch.mv(w.view(height,-1).data, v.data))\n",
    "        sigma = u.dot(w.view(height, -1).mv(v))\n",
    "        setattr(self.module, self.name, w / sigma.expand_as(w))\n",
    "\n",
    "    def _made_params(self):\n",
    "        try:\n",
    "            u = getattr(self.module, self.name + \"_u\")\n",
    "            v = getattr(self.module, self.name + \"_v\")\n",
    "            w = getattr(self.module, self.name + \"_bar\")\n",
    "            return True\n",
    "        except AttributeError:\n",
    "            return False\n",
    "\n",
    "    def _make_params(self):\n",
    "        w = getattr(self.module, self.name)\n",
    "\n",
    "        height = w.data.shape[0]\n",
    "        width = w.view(height, -1).data.shape[1]\n",
    "\n",
    "        u = Parameter(w.data.new(height).normal_(0, 1), requires_grad=False)\n",
    "        v = Parameter(w.data.new(width).normal_(0, 1), requires_grad=False)\n",
    "        u.data = l2normalize(u.data)\n",
    "        v.data = l2normalize(v.data)\n",
    "        w_bar = Parameter(w.data)\n",
    "\n",
    "        del self.module._parameters[self.name]\n",
    "\n",
    "        self.module.register_parameter(self.name + \"_u\", u)\n",
    "        self.module.register_parameter(self.name + \"_v\", v)\n",
    "        self.module.register_parameter(self.name + \"_bar\", w_bar)\n",
    "\n",
    "    def forward(self, *args):\n",
    "        self._update_u_v()\n",
    "        return self.module.forward(*args)\n",
    "\n",
    "\n",
    "\n",
    "def upconv(in_channels, out_channels, kernel_size, stride=2, padding=2, batch_norm=True, spectral_norm=False):\n",
    "    \"\"\"Creates a upsample-and-convolution layer, with optional batch normalization.\n",
    "    \"\"\"\n",
    "    layers = []\n",
    "    if stride>1:\n",
    "        layers.append(nn.Upsample(scale_factor=stride))\n",
    "    conv_layer = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=1, padding=padding, bias=False)\n",
    "    if spectral_norm:\n",
    "        layers.append(SpectralNorm(conv_layer))\n",
    "    else:\n",
    "        layers.append(conv_layer)\n",
    "    if batch_norm:\n",
    "        layers.append(nn.BatchNorm2d(out_channels))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def conv(in_channels, out_channels, kernel_size, stride=2, padding=2, batch_norm=True, init_zero_weights=False, spectral_norm=False):\n",
    "    \"\"\"Creates a convolutional layer, with optional batch normalization.\n",
    "    \"\"\"\n",
    "    layers = []\n",
    "    conv_layer = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
    "    if init_zero_weights:\n",
    "        conv_layer.weight.data = torch.randn(out_channels, in_channels, kernel_size, kernel_size) * 0.001\n",
    "\n",
    "    if spectral_norm:\n",
    "        layers.append(SpectralNorm(conv_layer))\n",
    "    else:\n",
    "        layers.append(conv_layer)\n",
    "\n",
    "    if batch_norm:\n",
    "        layers.append(nn.BatchNorm2d(out_channels))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, conv_dim):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv_layer = conv(in_channels=conv_dim, out_channels=conv_dim, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + self.conv_layer(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class DCGenerator(nn.Module):\n",
    "    def __init__(self, noise_size, conv_dim, spectral_norm=False):\n",
    "        super(DCGenerator, self).__init__()\n",
    "\n",
    "        self.conv_dim = conv_dim\n",
    "\n",
    "        self.linear_bn = nn.Sequential(nn.Linear(in_features=noise_size, out_features=conv_dim*4*4*4), nn.Flatten())\n",
    "\n",
    "        self.upconv1 =  upconv(in_channels=conv_dim*4, out_channels=conv_dim*2,\n",
    "                              kernel_size=5, stride=2, padding=2, spectral_norm=spectral_norm)\n",
    "        self.upconv2 = upconv(in_channels=conv_dim*2, out_channels=conv_dim,\n",
    "                              kernel_size=5, stride=2, padding=2, spectral_norm=spectral_norm)\n",
    "        self.upconv3 = upconv(in_channels=conv_dim, out_channels=3,\n",
    "                              kernel_size=5, stride=2, padding=2, batch_norm=False, spectral_norm=spectral_norm)\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"Generates an image given a sample of random noise.\n",
    "\n",
    "            Input\n",
    "            -----\n",
    "                z: BS x noise_size x 1 x 1   -->  BSx100x1x1 (during training)\n",
    "\n",
    "            Output\n",
    "            ------\n",
    "                out: BS x channels x image_width x image_height  -->  BSx3x32x32 (during training)\n",
    "        \"\"\"\n",
    "        batch_size = z.size(0)\n",
    "\n",
    "        z = z.view(-1, 100)\n",
    "        out = F.relu(self.linear_bn(z)).view(-1, self.conv_dim*4, 4, 4)    # BS x 128 x 4 x 4\n",
    "        out = F.relu(self.upconv1(out))  # BS x 64 x 8 x 8\n",
    "        out = F.relu(self.upconv2(out))  # BS x 32 x 16 x 16\n",
    "        out = F.tanh(self.upconv3(out))  # BS x 3 x 32 x 32\n",
    "\n",
    "        out_size = out.size()\n",
    "        if out_size != torch.Size([batch_size, 3, 32, 32]):\n",
    "            raise ValueError(\"expect {} x 3 x 32 x 32, but get {}\".format(batch_size, out_size))\n",
    "        return out\n",
    "\n",
    "\n",
    "class DCDiscriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, conv_dim=64, spectral_norm=False):\n",
    "        super(DCDiscriminator, self).__init__()\n",
    "\n",
    "        self.conv1 = conv(in_channels=3, out_channels=conv_dim, kernel_size=5, stride=2, spectral_norm=spectral_norm)\n",
    "        self.conv2 = conv(in_channels=conv_dim, out_channels=conv_dim*2, kernel_size=5, stride=2, spectral_norm=spectral_norm)\n",
    "        self.conv3 = conv(in_channels=conv_dim*2, out_channels=conv_dim*4, kernel_size=5, stride=2, spectral_norm=spectral_norm)\n",
    "        self.conv4 = conv(in_channels=conv_dim*4, out_channels=1, kernel_size=5, stride=2, padding=1, batch_norm=False, spectral_norm=spectral_norm)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        out = F.relu(self.conv1(x))    # BS x 64 x 16 x 16\n",
    "        out = F.relu(self.conv2(out))    # BS x 64 x 8 x 8\n",
    "        out = F.relu(self.conv3(out))    # BS x 64 x 4 x 4\n",
    "        out = self.conv4(out).squeeze()\n",
    "\n",
    "        out_size = out.size()\n",
    "        if out_size != torch.Size([batch_size,]):\n",
    "            raise ValueError(\"expect {} x 1, but get {}\".format(batch_size, out_size))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oil7MRiEM4mN"
   },
   "source": [
    "## utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jfZ-d7IBQfIw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "#from model import DCDiscriminator, DCGenerator\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def to_var(tensor, cuda=True):\n",
    "    \"\"\"Wraps a Tensor in a Variable, optionally placing it on the GPU.\n",
    "\n",
    "        Arguments:\n",
    "            tensor: A Tensor object.\n",
    "            cuda: A boolean flag indicating whether to use the GPU.\n",
    "\n",
    "        Returns:\n",
    "            A Variable object, on the GPU if cuda==True.\n",
    "    \"\"\"\n",
    "    if cuda:\n",
    "        return Variable(tensor.cuda())\n",
    "    else:\n",
    "        return Variable(tensor)\n",
    "\n",
    "\n",
    "def to_data(x):\n",
    "    \"\"\"Converts variable to numpy.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cpu()\n",
    "    return x.data.numpy()\n",
    "\n",
    "\n",
    "def create_dir(directory):\n",
    "    \"\"\"Creates a directory if it doesn't already exist.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "def gan_checkpoint(iteration, G, D, opts):\n",
    "    \"\"\"Saves the parameters of the generator G and discriminator D.\n",
    "    \"\"\"\n",
    "    G_path = os.path.join(opts.checkpoint_dir, f'G_{iteration}.pkl')\n",
    "    D_path = os.path.join(opts.checkpoint_dir, f'D_{iteration}.pkl')\n",
    "    torch.save(G.state_dict(), G_path)\n",
    "    torch.save(D.state_dict(), D_path)\n",
    "\n",
    "def load_checkpoint(opts, iteration):\n",
    "    \"\"\"Loads the generator and discriminator models from checkpoints.\n",
    "    \"\"\"\n",
    "    G_path = os.path.join(opts.load, f'G_{iteration}.pkl')\n",
    "    D_path = os.path.join(opts.load, f'D_{iteration}.pkl')\n",
    "\n",
    "    G = DCGenerator(noise_size=opts.noise_size, conv_dim=opts.g_conv_dim, spectral_norm=opts.spectral_norm)\n",
    "    D = DCDiscriminator(conv_dim=opts.d_conv_dim)\n",
    "\n",
    "    G.load_state_dict(torch.load(G_path, map_location=lambda storage, loc: storage))\n",
    "    D.load_state_dict(torch.load(D_path, map_location=lambda storage, loc: storage))\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        G.cuda()\n",
    "        D.cuda()\n",
    "        print('Models moved to GPU.')\n",
    "\n",
    "    return G, D\n",
    "\n",
    "\n",
    "def gan_save_samples(G, fixed_noise, iteration, opts):\n",
    "    generated_images = G(fixed_noise)\n",
    "    generated_images = to_data(generated_images)\n",
    "    # save images in sample dir\n",
    "\n",
    "def create_model(opts):\n",
    "    \"\"\"Builds the generators and discriminators.\n",
    "    \"\"\"\n",
    "    ### GAN\n",
    "    G = DCGenerator(noise_size=opts.noise_size, conv_dim=opts.g_conv_dim, spectral_norm=opts.spectral_norm)\n",
    "    D = DCDiscriminator(conv_dim=opts.d_conv_dim, spectral_norm=opts.spectral_norm)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        G.cuda()\n",
    "        D.cuda()\n",
    "        print('Models moved to GPU.')\n",
    "    return G, D\n",
    "\n",
    "def sample_noise(batch_size, dim):\n",
    "    \"\"\"\n",
    "    Generate a PyTorch Tensor of uniform random noise.\n",
    "\n",
    "    Input:\n",
    "    - batch_size: Integer giving the batch size of noise to generate.\n",
    "    - dim: Integer giving the dimension of noise to generate.\n",
    "\n",
    "    Output:\n",
    "    - A PyTorch Tensor of shape (batch_size, dim, 1, 1) containing uniform\n",
    "      random noise in the range (-1, 1).\n",
    "    \"\"\"\n",
    "    return to_var(torch.rand(batch_size, dim) * 2 - 1).unsqueeze(2).unsqueeze(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeWsaBSlQrzS"
   },
   "source": [
    "## dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "U1fqoQAbQfoq"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "def get_emoji_loader(train_path, test_path, batch_size, image_size):\n",
    "    transform = transforms.Compose([\n",
    "                    transforms.Resize(image_size),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                ])\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(train_path, transform)\n",
    "    test_dataset = datasets.ImageFolder(test_path, transform)\n",
    "\n",
    "    train_dloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_dloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_dloader, test_dloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jD8xzuLZQvlW"
   },
   "source": [
    "## train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jbUEJh0UQuru"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# from utils import create_dir, create_model, sample_noise, to_var, gan_save_samples, gan_checkpoint\n",
    "# from dataset import get_emoji_loader\n",
    "\n",
    "\n",
    "def gan_training_loop(dataloader, test_dataloader, opts):\n",
    "\n",
    "    G, D = create_model(opts)\n",
    "\n",
    "    g_params = G.parameters()  # Get generator parameters\n",
    "    d_params = D.parameters()  # Get discriminator parameters\n",
    "\n",
    "    g_optimizer = optim.Adam(g_params, opts.lr, [opts.beta1, opts.beta2])\n",
    "    d_optimizer = optim.Adam(d_params, opts.lr * 2., [opts.beta1, opts.beta2])\n",
    "\n",
    "    train_iter = iter(dataloader)\n",
    "\n",
    "    test_iter = iter(test_dataloader)\n",
    "\n",
    "    # Get some fixed data from domains X for sampling. These are images that are held\n",
    "    # constant throughout training, that allow us to inspect the model's performance.\n",
    "    fixed_noise = sample_noise(100, opts.noise_size)  # # 100 x noise_size x 1 x 1\n",
    "\n",
    "    iter_per_epoch = len(train_iter)\n",
    "    total_train_iters = opts.train_iters\n",
    "\n",
    "    losses = {\"iteration\": [], \"D_fake_loss\": [], \"D_real_loss\": [], \"G_loss\": []}\n",
    "    loss = torch.nn.MSELoss()\n",
    "\n",
    "    try:\n",
    "        for iteration in range(1, opts.train_iters + 1):\n",
    "\n",
    "            # Reset data_iter for each epoch\n",
    "            if iteration % iter_per_epoch == 0:\n",
    "                train_iter = iter(dataloader)\n",
    "\n",
    "            real_images, real_labels = next(train_iter)\n",
    "            real_images, real_labels = to_var(real_images), to_var(real_labels).long().squeeze()\n",
    "\n",
    "            # ones = Variable(torch.Tensor(real_images.shape[0]).float().cuda().fill_(1.0), requires_grad=False)\n",
    "\n",
    "            for d_i in range(opts.d_train_iters):\n",
    "                d_optimizer.zero_grad()\n",
    "\n",
    "                # FILL THIS IN\n",
    "                # 1. Compute the discriminator loss on real images\n",
    "\n",
    "                D_out_real = D(real_images).type(torch.FloatTensor)\n",
    "                ones = torch.ones(size=real_labels.size()).type(torch.FloatTensor)\n",
    "                ones.requires_grad = False\n",
    "                zeros = torch.zeros(size=real_labels.size()).type(torch.FloatTensor)\n",
    "                zeros.requires_grad = False\n",
    "\n",
    "                D_real_loss = loss(D_out_real, zeros)\n",
    "                D_real_loss = D_real_loss.type(torch.FloatTensor)*(1/D_out_real.shape[0])\n",
    "                real_labels = real_labels.type(torch.FloatTensor)\n",
    "\n",
    "                # 2. Sample noise\n",
    "                noise = sample_noise(batch_size=opts.batch_size, dim=opts.noise_size)\n",
    "\n",
    "                # 3. Generate fake images from the noise\n",
    "                fake_images = G(noise)\n",
    "\n",
    "                # 4. Compute the discriminator loss on the fake images\n",
    "                D_out_fake = D(fake_images).type(torch.FloatTensor)\n",
    "                ones = torch.ones(size=D_out_fake.shape).type(torch.FloatTensor)\n",
    "                ones.requires_grad = False\n",
    "                D_fake_loss =loss(D_out_fake, ones)\n",
    "                D_fake_loss = D_fake_loss.type(torch.FloatTensor)*(1/D_out_fake.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "                # 5. Compute the total discriminator loss\n",
    "                D_total_loss = D_fake_loss + D_real_loss\n",
    "                D_total_loss = D_total_loss.type(torch.FloatTensor)\n",
    "                D_total_loss.backward()\n",
    "                d_optimizer.step()\n",
    "\n",
    "\n",
    "            ###########################################\n",
    "            ###          TRAIN THE GENERATOR        ###\n",
    "            ###########################################\n",
    "\n",
    "            g_optimizer.zero_grad()\n",
    "\n",
    "            # FILL THIS IN\n",
    "            # 1. Sample noise\n",
    "            noise = sample_noise(batch_size=opts.batch_size, dim=opts.noise_size)\n",
    "\n",
    "            # 2. Generate fake images from the noise\n",
    "            fake_images = G(noise)\n",
    "\n",
    "            # 3. Compute the generator loss\n",
    "            D_out_fake1 = D(fake_images).type(torch.FloatTensor)\n",
    "            zeros = torch.zeros(size=D_out_fake1.shape).type(torch.FloatTensor)\n",
    "            zeros.requires_grad = False\n",
    "            G_loss = loss(D_out_fake1, zeros)\n",
    "            G_loss = G_loss.type(torch.FloatTensor)*(1/D_out_fake1.shape[0])\n",
    "\n",
    "            G_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "            # Print the log info\n",
    "            if iteration % opts.log_step == 0:\n",
    "                losses['iteration'].append(iteration)\n",
    "                losses['D_real_loss'].append(D_real_loss.item())\n",
    "                losses['D_fake_loss'].append(D_fake_loss.item())\n",
    "                losses['G_loss'].append(G_loss.item())\n",
    "                print('Iteration [{:4d}/{:4d}] | D_real_loss: {:6.4f} | D_fake_loss: {:6.4f} | G_loss: {:6.4f}'.format(\n",
    "                    iteration, total_train_iters, D_real_loss.item(), D_fake_loss.item(), G_loss.item()))\n",
    "\n",
    "            # Save the generated samples\n",
    "            if iteration % opts.sample_every == 0:\n",
    "                gan_save_samples(G, fixed_noise, iteration, opts)\n",
    "\n",
    "            # Save the model parameters\n",
    "            if iteration % opts.checkpoint_every == 0:\n",
    "                gan_checkpoint(iteration, G, D, opts)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print('Exiting early from training.')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(losses['iteration'], losses['D_real_loss'], label='D_real')\n",
    "    plt.plot(losses['iteration'], losses['D_fake_loss'], label='D_fake')\n",
    "    plt.plot(losses['iteration'], losses['G_loss'], label='G')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(opts.sample_dir, f'losses_{opts.lr}_{opts.d_train_iters}_{opts.spectral_norm}_.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(opts):\n",
    "\n",
    "    dataloader_X, test_dataloader_X = get_emoji_loader(opts.train_path, opts.test_path, opts.batch_size, opts.image_size)\n",
    "\n",
    "    # Set the random seed manually for reproducibility.\n",
    "    # ......\n",
    "\n",
    "    create_dir(opts.checkpoint_dir)\n",
    "    create_dir(opts.sample_dir)\n",
    "\n",
    "    gan_training_loop(dataloader_X, test_dataloader_X, opts)\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # Load config file\n",
    "#     args = {\n",
    "#               'image_size':32,\n",
    "#               'g_conv_dim':32,\n",
    "#               'd_conv_dim':64,\n",
    "#               'noise_size':100,\n",
    "#               'train_iters':15000,\n",
    "#               'train_path':'/content/drive/MyDrive/emojis/Apple',\n",
    "#               'test_path': '/content/drive/MyDrive/emojis/Test_Apple',\n",
    "#               'lr':0.0005,\n",
    "#               'beta1':0.5,\n",
    "#               'beta2':0.999,\n",
    "#               'batch_size':64,\n",
    "#               'checkpoint_dir': '/content/drive/MyDrive/emojis/checkpoints',\n",
    "#               'sample_dir': '/content/drive/MyDrive/emojis/samples',\n",
    "#               'load': None,\n",
    "#               'log_step':200,\n",
    "#               'sample_every':1000,\n",
    "#               'checkpoint_every':1000,\n",
    "#               'spectral_norm': False,\n",
    "#               'gradient_penalty': False,\n",
    "#               'd_train_iters': 1\n",
    "# }\n",
    "#     train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qzHPKQtByrKY",
    "outputId": "4ac71046-b999-4fba-b96e-72c8f6068049"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting access-dict-by-dot\n",
      "  Downloading access_dict_by_dot-0.0.4.tar.gz (1.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: access-dict-by-dot\n",
      "  Building wheel for access-dict-by-dot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for access-dict-by-dot: filename=access_dict_by_dot-0.0.4-py3-none-any.whl size=2237 sha256=91bc402d134bcd4004c4b5ec5ff32553766b68c6876f5d6fb085cec5463bf883\n",
      "  Stored in directory: /root/.cache/pip/wheels/ff/e4/ac/0b2f8e9a6df7fe262ed95622941605a1bb69da435a4013db74\n",
      "Successfully built access-dict-by-dot\n",
      "Installing collected packages: access-dict-by-dot\n",
      "Successfully installed access-dict-by-dot-0.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install access-dict-by-dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kEIQsAhHRr3B",
    "outputId": "7d48dca7-bc13-496a-a259-cc59a6881cbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models moved to GPU.\n",
      "Iteration [ 200/10000] | D_real_loss: 0.0007 | D_fake_loss: 0.0024 | G_loss: 0.0145\n",
      "Iteration [ 400/10000] | D_real_loss: 0.0012 | D_fake_loss: 0.0011 | G_loss: 0.0090\n",
      "Iteration [ 600/10000] | D_real_loss: 0.0009 | D_fake_loss: 0.0045 | G_loss: 0.0157\n",
      "Iteration [ 800/10000] | D_real_loss: 0.0019 | D_fake_loss: 0.0005 | G_loss: 0.0090\n",
      "Iteration [1000/10000] | D_real_loss: 0.0018 | D_fake_loss: 0.0012 | G_loss: 0.0049\n",
      "Iteration [1200/10000] | D_real_loss: 0.0009 | D_fake_loss: 0.0014 | G_loss: 0.0105\n",
      "Iteration [1400/10000] | D_real_loss: 0.0009 | D_fake_loss: 0.0018 | G_loss: 0.0312\n",
      "Iteration [1600/10000] | D_real_loss: 0.0009 | D_fake_loss: 0.0009 | G_loss: 0.0234\n",
      "Iteration [1800/10000] | D_real_loss: 0.0036 | D_fake_loss: 0.0025 | G_loss: 0.0072\n",
      "Iteration [2000/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0007 | G_loss: 0.0088\n",
      "Iteration [2200/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0003 | G_loss: 0.0158\n",
      "Iteration [2400/10000] | D_real_loss: 0.0005 | D_fake_loss: 0.0014 | G_loss: 0.0167\n",
      "Iteration [2600/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0001 | G_loss: 0.0166\n",
      "Iteration [2800/10000] | D_real_loss: 0.0004 | D_fake_loss: 0.0002 | G_loss: 0.0173\n",
      "Iteration [3000/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0001 | G_loss: 0.0185\n",
      "Iteration [3200/10000] | D_real_loss: 0.0010 | D_fake_loss: 0.0002 | G_loss: 0.0094\n",
      "Iteration [3400/10000] | D_real_loss: 0.0004 | D_fake_loss: 0.0002 | G_loss: 0.0121\n",
      "Iteration [3600/10000] | D_real_loss: 0.0007 | D_fake_loss: 0.0003 | G_loss: 0.0139\n",
      "Iteration [3800/10000] | D_real_loss: 0.0007 | D_fake_loss: 0.0004 | G_loss: 0.0149\n",
      "Iteration [4000/10000] | D_real_loss: 0.0007 | D_fake_loss: 0.0002 | G_loss: 0.0152\n",
      "Iteration [4200/10000] | D_real_loss: 0.0003 | D_fake_loss: 0.0010 | G_loss: 0.0182\n",
      "Iteration [4400/10000] | D_real_loss: 0.0004 | D_fake_loss: 0.0015 | G_loss: 0.0073\n",
      "Iteration [4600/10000] | D_real_loss: 0.0003 | D_fake_loss: 0.0001 | G_loss: 0.0148\n",
      "Iteration [4800/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0180\n",
      "Iteration [5000/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0003 | G_loss: 0.0222\n",
      "Iteration [5200/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0148\n",
      "Iteration [5400/10000] | D_real_loss: 0.0009 | D_fake_loss: 0.0002 | G_loss: 0.0161\n",
      "Iteration [5600/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0133\n",
      "Iteration [5800/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0002 | G_loss: 0.0159\n",
      "Iteration [6000/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0003 | G_loss: 0.0227\n",
      "Iteration [6200/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0143\n",
      "Iteration [6400/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0001 | G_loss: 0.0126\n",
      "Iteration [6600/10000] | D_real_loss: 0.0004 | D_fake_loss: 0.0000 | G_loss: 0.0133\n",
      "Iteration [6800/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0161\n",
      "Iteration [7000/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0182\n",
      "Iteration [7200/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0000 | G_loss: 0.0170\n",
      "Iteration [7400/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0173\n",
      "Iteration [7600/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0002 | G_loss: 0.0151\n",
      "Iteration [7800/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0001 | G_loss: 0.0128\n",
      "Iteration [8000/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0002 | G_loss: 0.0165\n",
      "Iteration [8200/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0000 | G_loss: 0.0142\n",
      "Iteration [8400/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0171\n",
      "Iteration [8600/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0156\n",
      "Iteration [8800/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0001 | G_loss: 0.0188\n",
      "Iteration [9000/10000] | D_real_loss: 0.0007 | D_fake_loss: 0.0002 | G_loss: 0.0201\n",
      "Iteration [9200/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0161\n",
      "Iteration [9400/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0001 | G_loss: 0.0183\n",
      "Iteration [9600/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0179\n",
      "Iteration [9800/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0170\n",
      "Iteration [10000/10000] | D_real_loss: 0.0005 | D_fake_loss: 0.0000 | G_loss: 0.0131\n"
     ]
    }
   ],
   "source": [
    "from access_dict_by_dot import AccessDictByDot\n",
    "\n",
    "args = {\n",
    "              'image_size':32,\n",
    "              'g_conv_dim':32,\n",
    "              'd_conv_dim':64,\n",
    "              'noise_size':100,\n",
    "              'train_iters':10000,\n",
    "              'train_path': '/content/drive/MyDrive/Apple/',\n",
    "              \"test_path\": '/content/drive/MyDrive/emojis/Test_Apple',\n",
    "              'lr':0.0005,\n",
    "              'beta1':0.5,\n",
    "              'beta2':0.999,\n",
    "              'batch_size':64,\n",
    "              'checkpoint_dir': '/content/drive/MyDrive/emojis/checkpoints',\n",
    "              'sample_dir': '/content/drive/MyDrive/emojis/samples',\n",
    "              'load': None,\n",
    "              'log_step':200,\n",
    "              'sample_every':1000,\n",
    "              'checkpoint_every':1000,\n",
    "              'spectral_norm': False,\n",
    "              'gradient_penalty': False,\n",
    "              'd_train_iters': 1\n",
    "}\n",
    "args = AccessDictByDot.load(args)\n",
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uo_c8gV0dhYA",
    "outputId": "59fb7b6a-dff1-4836-ecf7-dd871332d3e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models moved to GPU.\n",
      "Iteration [ 200/10000] | D_real_loss: 0.0037 | D_fake_loss: 0.0141 | G_loss: 0.0649\n",
      "Iteration [ 400/10000] | D_real_loss: 0.0011 | D_fake_loss: 0.0007 | G_loss: 0.0132\n",
      "Iteration [ 600/10000] | D_real_loss: 0.0007 | D_fake_loss: 0.0020 | G_loss: 0.0160\n",
      "Iteration [ 800/10000] | D_real_loss: 0.0014 | D_fake_loss: 0.0003 | G_loss: 0.0118\n",
      "Iteration [1000/10000] | D_real_loss: 0.0010 | D_fake_loss: 0.0003 | G_loss: 0.0138\n",
      "Iteration [1200/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0004 | G_loss: 0.0195\n",
      "Iteration [1400/10000] | D_real_loss: 0.0006 | D_fake_loss: 0.0003 | G_loss: 0.0142\n",
      "Iteration [1600/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0004 | G_loss: 0.0202\n",
      "Iteration [1800/10000] | D_real_loss: 0.0005 | D_fake_loss: 0.0010 | G_loss: 0.0247\n",
      "Iteration [2000/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0003 | G_loss: 0.0177\n",
      "Iteration [2200/10000] | D_real_loss: 0.0006 | D_fake_loss: 0.0002 | G_loss: 0.0157\n",
      "Iteration [2400/10000] | D_real_loss: 0.0006 | D_fake_loss: 0.0009 | G_loss: 0.0206\n",
      "Iteration [2600/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0003 | G_loss: 0.0173\n",
      "Iteration [2800/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0002 | G_loss: 0.0179\n",
      "Iteration [3000/10000] | D_real_loss: 0.0003 | D_fake_loss: 0.0003 | G_loss: 0.0141\n",
      "Iteration [3200/10000] | D_real_loss: 0.0003 | D_fake_loss: 0.0024 | G_loss: 0.0192\n",
      "Iteration [3400/10000] | D_real_loss: 0.0006 | D_fake_loss: 0.0002 | G_loss: 0.0111\n",
      "Iteration [3600/10000] | D_real_loss: 0.0022 | D_fake_loss: 0.0037 | G_loss: 0.0398\n",
      "Iteration [3800/10000] | D_real_loss: 0.0003 | D_fake_loss: 0.0002 | G_loss: 0.0179\n",
      "Iteration [4000/10000] | D_real_loss: 0.0010 | D_fake_loss: 0.0008 | G_loss: 0.0108\n",
      "Iteration [4200/10000] | D_real_loss: 0.0003 | D_fake_loss: 0.0002 | G_loss: 0.0141\n",
      "Iteration [4400/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0002 | G_loss: 0.0158\n",
      "Iteration [4600/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0002 | G_loss: 0.0222\n",
      "Iteration [4800/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0002 | G_loss: 0.0145\n",
      "Iteration [5000/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0004 | G_loss: 0.0134\n",
      "Iteration [5200/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0002 | G_loss: 0.0139\n",
      "Iteration [5400/10000] | D_real_loss: 0.0004 | D_fake_loss: 0.0003 | G_loss: 0.0205\n",
      "Iteration [5600/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0003 | G_loss: 0.0144\n",
      "Iteration [5800/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0157\n",
      "Iteration [6000/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0127\n",
      "Iteration [6200/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0001 | G_loss: 0.0160\n",
      "Iteration [6400/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0172\n",
      "Iteration [6600/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0193\n",
      "Iteration [6800/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0008 | G_loss: 0.0219\n",
      "Iteration [7000/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0004 | G_loss: 0.0172\n",
      "Iteration [7200/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0002 | G_loss: 0.0226\n",
      "Iteration [7400/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0004 | G_loss: 0.0179\n",
      "Iteration [7600/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0000 | G_loss: 0.0165\n",
      "Iteration [7800/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0011 | G_loss: 0.0183\n",
      "Iteration [8000/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0002 | G_loss: 0.0158\n",
      "Iteration [8200/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0001 | G_loss: 0.0130\n",
      "Iteration [8400/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0001 | G_loss: 0.0151\n",
      "Iteration [8600/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0002 | G_loss: 0.0195\n",
      "Iteration [8800/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0000 | G_loss: 0.0135\n",
      "Iteration [9000/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0161\n",
      "Iteration [9200/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0148\n",
      "Iteration [9400/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0000 | G_loss: 0.0170\n",
      "Iteration [9600/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0005 | G_loss: 0.0214\n",
      "Iteration [9800/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0143\n",
      "Iteration [10000/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0206\n"
     ]
    }
   ],
   "source": [
    "from access_dict_by_dot import AccessDictByDot\n",
    "\n",
    "args = {\n",
    "              'image_size':32,\n",
    "              'g_conv_dim':32,\n",
    "              'd_conv_dim':64,\n",
    "              'noise_size':100,\n",
    "              'train_iters':10000,\n",
    "              'train_path': '/content/drive/MyDrive/Apple/',\n",
    "              \"test_path\": '/content/drive/MyDrive/emojis/Test_Apple',\n",
    "              'lr':0.0005,\n",
    "              'beta1':0.5,\n",
    "              'beta2':0.999,\n",
    "              'batch_size':64,\n",
    "              'checkpoint_dir': '/content/drive/MyDrive/emojis/checkpoints',\n",
    "              'sample_dir': '/content/drive/MyDrive/emojis/samples',\n",
    "              'load': None,\n",
    "              'log_step':200,\n",
    "              'sample_every':1000,\n",
    "              'checkpoint_every':1000,\n",
    "              'spectral_norm': True,\n",
    "              'gradient_penalty': False,\n",
    "              'd_train_iters': 1\n",
    "}\n",
    "args = AccessDictByDot.load(args)\n",
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "K14IaC3rp135",
    "outputId": "18cfa253-e812-4560-c290-d4e41ebf13df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models moved to GPU.\n",
      "Iteration [ 200/10000] | D_real_loss: 0.0029 | D_fake_loss: 0.0032 | G_loss: 0.0158\n",
      "Iteration [ 400/10000] | D_real_loss: 0.0016 | D_fake_loss: 0.0122 | G_loss: 0.0432\n",
      "Iteration [ 600/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0028 | G_loss: 0.0066\n",
      "Iteration [ 800/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0003 | G_loss: 0.0123\n",
      "Iteration [1000/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0020 | G_loss: 0.0305\n",
      "Iteration [1200/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0002 | G_loss: 0.0122\n",
      "Iteration [1400/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0011 | G_loss: 0.0263\n",
      "Iteration [1600/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0000 | G_loss: 0.0171\n",
      "Iteration [1800/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0006 | G_loss: 0.0230\n",
      "Iteration [2000/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0006 | G_loss: 0.0117\n",
      "Iteration [2200/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0162\n",
      "Iteration [2400/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0152\n",
      "Iteration [2600/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0004 | G_loss: 0.0216\n",
      "Iteration [2800/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0008 | G_loss: 0.0096\n",
      "Iteration [3000/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0146\n",
      "Iteration [3200/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0001 | G_loss: 0.0183\n",
      "Iteration [3400/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0002 | G_loss: 0.0123\n",
      "Iteration [3600/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0001 | G_loss: 0.0136\n",
      "Iteration [3800/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0006 | G_loss: 0.0101\n",
      "Iteration [4000/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0001 | G_loss: 0.0190\n",
      "Iteration [4200/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0156\n",
      "Iteration [4400/10000] | D_real_loss: 0.4788 | D_fake_loss: 0.0000 | G_loss: 0.0079\n",
      "Iteration [4600/10000] | D_real_loss: 0.0887 | D_fake_loss: 0.0014 | G_loss: 0.0089\n",
      "Iteration [4800/10000] | D_real_loss: 0.0437 | D_fake_loss: 0.0002 | G_loss: 0.0224\n",
      "Iteration [5000/10000] | D_real_loss: 0.0717 | D_fake_loss: 0.0028 | G_loss: 0.0066\n",
      "Iteration [5200/10000] | D_real_loss: 0.0378 | D_fake_loss: 0.0001 | G_loss: 0.0181\n",
      "Iteration [5400/10000] | D_real_loss: 0.0313 | D_fake_loss: 0.0000 | G_loss: 0.0208\n",
      "Iteration [5600/10000] | D_real_loss: 0.0259 | D_fake_loss: 0.0000 | G_loss: 0.0160\n",
      "Iteration [5800/10000] | D_real_loss: 0.0146 | D_fake_loss: 0.0002 | G_loss: 0.0073\n",
      "Iteration [6000/10000] | D_real_loss: 0.0092 | D_fake_loss: 0.0003 | G_loss: 0.0147\n",
      "Iteration [6200/10000] | D_real_loss: 0.0353 | D_fake_loss: 0.0009 | G_loss: 0.0250\n",
      "Iteration [6400/10000] | D_real_loss: 0.0117 | D_fake_loss: 0.0002 | G_loss: 0.0242\n",
      "Iteration [6600/10000] | D_real_loss: 0.0060 | D_fake_loss: 0.0001 | G_loss: 0.0161\n",
      "Iteration [6800/10000] | D_real_loss: 0.0095 | D_fake_loss: 0.0000 | G_loss: 0.0141\n",
      "Iteration [7000/10000] | D_real_loss: 0.0041 | D_fake_loss: 0.0000 | G_loss: 0.0141\n",
      "Iteration [7200/10000] | D_real_loss: 0.0056 | D_fake_loss: 0.0000 | G_loss: 0.0173\n",
      "Iteration [7400/10000] | D_real_loss: 0.0062 | D_fake_loss: 0.0000 | G_loss: 0.0147\n",
      "Iteration [7600/10000] | D_real_loss: 0.0013 | D_fake_loss: 0.0001 | G_loss: 0.0136\n",
      "Iteration [7800/10000] | D_real_loss: 0.0024 | D_fake_loss: 0.0001 | G_loss: 0.0144\n",
      "Iteration [8000/10000] | D_real_loss: 0.0007 | D_fake_loss: 0.0001 | G_loss: 0.0190\n",
      "Iteration [8200/10000] | D_real_loss: 0.0028 | D_fake_loss: 0.0000 | G_loss: 0.0149\n",
      "Iteration [8400/10000] | D_real_loss: 0.0023 | D_fake_loss: 0.0000 | G_loss: 0.0146\n",
      "Iteration [8600/10000] | D_real_loss: 0.0006 | D_fake_loss: 0.0000 | G_loss: 0.0153\n",
      "Iteration [8800/10000] | D_real_loss: 0.0100 | D_fake_loss: 0.0003 | G_loss: 0.0200\n",
      "Iteration [9000/10000] | D_real_loss: 0.0018 | D_fake_loss: 0.0007 | G_loss: 0.0181\n",
      "Iteration [9200/10000] | D_real_loss: 0.0003 | D_fake_loss: 0.0000 | G_loss: 0.0148\n",
      "Iteration [9400/10000] | D_real_loss: 0.0015 | D_fake_loss: 0.0000 | G_loss: 0.0147\n",
      "Iteration [9600/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0174\n",
      "Iteration [9800/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0004 | G_loss: 0.0140\n",
      "Iteration [10000/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0000 | G_loss: 0.0160\n"
     ]
    }
   ],
   "source": [
    "from access_dict_by_dot import AccessDictByDot\n",
    "\n",
    "args = {\n",
    "              'image_size':32,\n",
    "              'g_conv_dim':32,\n",
    "              'd_conv_dim':64,\n",
    "              'noise_size':100,\n",
    "              'train_iters':10000,\n",
    "              'train_path': '/content/drive/MyDrive/Apple/',\n",
    "              \"test_path\": '/content/drive/MyDrive/emojis/Test_Apple',\n",
    "              'lr':0.1,\n",
    "              'beta1':0.5,\n",
    "              'beta2':0.999,\n",
    "              'batch_size':64,\n",
    "              'checkpoint_dir': '/content/drive/MyDrive/emojis/checkpoints',\n",
    "              'sample_dir': '/content/drive/MyDrive/emojis/samples',\n",
    "              'load': None,\n",
    "              'log_step':200,\n",
    "              'sample_every':1000,\n",
    "              'checkpoint_every':1000,\n",
    "              'spectral_norm': False,\n",
    "              'gradient_penalty': False,\n",
    "              'd_train_iters': 1\n",
    "}\n",
    "args = AccessDictByDot.load(args)\n",
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wYXkf7Lxp4YY",
    "outputId": "d8ec1327-5b10-42b3-c264-761a3baaae1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models moved to GPU.\n",
      "Iteration [ 200/10000] | D_real_loss: 0.0392 | D_fake_loss: 0.0070 | G_loss: 0.0092\n",
      "Iteration [ 400/10000] | D_real_loss: 0.0010 | D_fake_loss: 0.0027 | G_loss: 0.0217\n",
      "Iteration [ 600/10000] | D_real_loss: 0.0005 | D_fake_loss: 0.0003 | G_loss: 0.0149\n",
      "Iteration [ 800/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0001 | G_loss: 0.0153\n",
      "Iteration [1000/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0005 | G_loss: 0.0149\n",
      "Iteration [1200/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0012 | G_loss: 0.0160\n",
      "Iteration [1400/10000] | D_real_loss: 0.0012 | D_fake_loss: 0.0076 | G_loss: 0.0193\n",
      "Iteration [1600/10000] | D_real_loss: 0.0027 | D_fake_loss: 0.0005 | G_loss: 0.0063\n",
      "Iteration [1800/10000] | D_real_loss: 0.0033 | D_fake_loss: 0.0093 | G_loss: 0.0116\n",
      "Iteration [2000/10000] | D_real_loss: 0.0004 | D_fake_loss: 0.0008 | G_loss: 0.0136\n",
      "Iteration [2200/10000] | D_real_loss: 0.0003 | D_fake_loss: 0.0001 | G_loss: 0.0137\n",
      "Iteration [2400/10000] | D_real_loss: 0.0005 | D_fake_loss: 0.0002 | G_loss: 0.0139\n",
      "Iteration [2600/10000] | D_real_loss: 0.0010 | D_fake_loss: 0.0010 | G_loss: 0.0132\n",
      "Iteration [2800/10000] | D_real_loss: 0.0023 | D_fake_loss: 0.0003 | G_loss: 0.0073\n",
      "Iteration [3000/10000] | D_real_loss: 0.0009 | D_fake_loss: 0.0061 | G_loss: 0.0148\n",
      "Iteration [3200/10000] | D_real_loss: 0.0005 | D_fake_loss: 0.0005 | G_loss: 0.0222\n",
      "Iteration [3400/10000] | D_real_loss: 0.0006 | D_fake_loss: 0.0005 | G_loss: 0.0197\n",
      "Iteration [3600/10000] | D_real_loss: 0.0014 | D_fake_loss: 0.0041 | G_loss: 0.0110\n",
      "Iteration [3800/10000] | D_real_loss: 0.0007 | D_fake_loss: 0.0003 | G_loss: 0.0175\n",
      "Iteration [4000/10000] | D_real_loss: 0.0010 | D_fake_loss: 0.0003 | G_loss: 0.0138\n",
      "Iteration [4200/10000] | D_real_loss: 0.0006 | D_fake_loss: 0.0002 | G_loss: 0.0142\n",
      "Iteration [4400/10000] | D_real_loss: 0.0003 | D_fake_loss: 0.0004 | G_loss: 0.0188\n",
      "Iteration [4600/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0002 | G_loss: 0.0188\n",
      "Iteration [4800/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0001 | G_loss: 0.0158\n",
      "Iteration [5000/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0145\n",
      "Iteration [5200/10000] | D_real_loss: 0.0003 | D_fake_loss: 0.0000 | G_loss: 0.0163\n",
      "Iteration [5400/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0145 | G_loss: 0.0010\n",
      "Iteration [5600/10000] | D_real_loss: 0.0005 | D_fake_loss: 0.0135 | G_loss: 0.0008\n",
      "Iteration [5800/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0118 | G_loss: 0.0029\n",
      "Iteration [6000/10000] | D_real_loss: 0.0003 | D_fake_loss: 0.0077 | G_loss: 0.0046\n",
      "Iteration [6200/10000] | D_real_loss: 0.0015 | D_fake_loss: 0.0054 | G_loss: 0.0201\n",
      "Iteration [6400/10000] | D_real_loss: 0.0024 | D_fake_loss: 0.0015 | G_loss: 0.0072\n",
      "Iteration [6600/10000] | D_real_loss: 0.0006 | D_fake_loss: 0.0004 | G_loss: 0.0203\n",
      "Iteration [6800/10000] | D_real_loss: 0.0029 | D_fake_loss: 0.0015 | G_loss: 0.0154\n",
      "Iteration [7000/10000] | D_real_loss: 0.0038 | D_fake_loss: 0.0032 | G_loss: 0.0068\n",
      "Iteration [7200/10000] | D_real_loss: 0.0012 | D_fake_loss: 0.0036 | G_loss: 0.0095\n",
      "Iteration [7400/10000] | D_real_loss: 0.0005 | D_fake_loss: 0.0036 | G_loss: 0.0054\n",
      "Iteration [7600/10000] | D_real_loss: 0.0021 | D_fake_loss: 0.0035 | G_loss: 0.0063\n",
      "Iteration [7800/10000] | D_real_loss: 0.0004 | D_fake_loss: 0.0000 | G_loss: 0.0152\n",
      "Iteration [8000/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0153\n",
      "Iteration [8200/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0160\n",
      "Iteration [8400/10000] | D_real_loss: 0.0007 | D_fake_loss: 0.0004 | G_loss: 0.0143\n",
      "Iteration [8600/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0157\n",
      "Iteration [8800/10000] | D_real_loss: 0.0004 | D_fake_loss: 0.0002 | G_loss: 0.0140\n",
      "Iteration [9000/10000] | D_real_loss: 0.0007 | D_fake_loss: 0.0011 | G_loss: 0.0149\n",
      "Iteration [9200/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0005 | G_loss: 0.0233\n",
      "Iteration [9400/10000] | D_real_loss: 0.0004 | D_fake_loss: 0.0002 | G_loss: 0.0109\n",
      "Iteration [9600/10000] | D_real_loss: 0.0009 | D_fake_loss: 0.0047 | G_loss: 0.0051\n",
      "Iteration [9800/10000] | D_real_loss: 0.0015 | D_fake_loss: 0.0005 | G_loss: 0.0140\n",
      "Iteration [10000/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0002 | G_loss: 0.0180\n"
     ]
    }
   ],
   "source": [
    "from access_dict_by_dot import AccessDictByDot\n",
    "\n",
    "args = {\n",
    "              'image_size':32,\n",
    "              'g_conv_dim':32,\n",
    "              'd_conv_dim':64,\n",
    "              'noise_size':100,\n",
    "              'train_iters':10000,\n",
    "              'train_path': '/content/drive/MyDrive/Apple/',\n",
    "              \"test_path\": '/content/drive/MyDrive/emojis/Test_Apple',\n",
    "              'lr':0.01,\n",
    "              'beta1':0.5,\n",
    "              'beta2':0.999,\n",
    "              'batch_size':64,\n",
    "              'checkpoint_dir': '/content/drive/MyDrive/emojis/checkpoints',\n",
    "              'sample_dir': '/content/drive/MyDrive/emojis/samples',\n",
    "              'load': None,\n",
    "              'log_step':200,\n",
    "              'sample_every':1000,\n",
    "              'checkpoint_every':1000,\n",
    "              'spectral_norm': False,\n",
    "              'gradient_penalty': False,\n",
    "              'd_train_iters': 1\n",
    "}\n",
    "args = AccessDictByDot.load(args)\n",
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tf9rif9Fp7yj",
    "outputId": "9d06820a-91b5-4ccc-8e94-7b9edf9009af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models moved to GPU.\n",
      "Iteration [ 200/10000] | D_real_loss: 0.0031 | D_fake_loss: 0.0005 | G_loss: 0.0075\n",
      "Iteration [ 400/10000] | D_real_loss: 0.0022 | D_fake_loss: 0.0048 | G_loss: 0.0118\n",
      "Iteration [ 600/10000] | D_real_loss: 0.0045 | D_fake_loss: 0.0006 | G_loss: 0.0038\n",
      "Iteration [ 800/10000] | D_real_loss: 0.0012 | D_fake_loss: 0.0018 | G_loss: 0.0118\n",
      "Iteration [1000/10000] | D_real_loss: 0.0006 | D_fake_loss: 0.0024 | G_loss: 0.0145\n",
      "Iteration [1200/10000] | D_real_loss: 0.0007 | D_fake_loss: 0.0004 | G_loss: 0.0185\n",
      "Iteration [1400/10000] | D_real_loss: 0.0004 | D_fake_loss: 0.0005 | G_loss: 0.0157\n",
      "Iteration [1600/10000] | D_real_loss: 0.0004 | D_fake_loss: 0.0036 | G_loss: 0.0077\n",
      "Iteration [1800/10000] | D_real_loss: 0.0023 | D_fake_loss: 0.0031 | G_loss: 0.0305\n",
      "Iteration [2000/10000] | D_real_loss: 0.0007 | D_fake_loss: 0.0007 | G_loss: 0.0212\n",
      "Iteration [2200/10000] | D_real_loss: 0.0003 | D_fake_loss: 0.0002 | G_loss: 0.0126\n",
      "Iteration [2400/10000] | D_real_loss: 0.0013 | D_fake_loss: 0.0002 | G_loss: 0.0088\n",
      "Iteration [2600/10000] | D_real_loss: 0.0004 | D_fake_loss: 0.0004 | G_loss: 0.0200\n",
      "Iteration [2800/10000] | D_real_loss: 0.0008 | D_fake_loss: 0.0003 | G_loss: 0.0116\n",
      "Iteration [3000/10000] | D_real_loss: 0.0012 | D_fake_loss: 0.0029 | G_loss: 0.0354\n",
      "Iteration [3200/10000] | D_real_loss: 0.0003 | D_fake_loss: 0.0004 | G_loss: 0.0184\n",
      "Iteration [3400/10000] | D_real_loss: 0.0005 | D_fake_loss: 0.0007 | G_loss: 0.0172\n",
      "Iteration [3600/10000] | D_real_loss: 0.0006 | D_fake_loss: 0.0002 | G_loss: 0.0125\n",
      "Iteration [3800/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0002 | G_loss: 0.0154\n",
      "Iteration [4000/10000] | D_real_loss: 0.0003 | D_fake_loss: 0.0001 | G_loss: 0.0193\n",
      "Iteration [4200/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0005 | G_loss: 0.0185\n",
      "Iteration [4400/10000] | D_real_loss: 0.0021 | D_fake_loss: 0.0009 | G_loss: 0.0079\n",
      "Iteration [4600/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0145\n",
      "Iteration [4800/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0002 | G_loss: 0.0187\n",
      "Iteration [5000/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0188\n",
      "Iteration [5200/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0000 | G_loss: 0.0151\n",
      "Iteration [5400/10000] | D_real_loss: 0.0003 | D_fake_loss: 0.0001 | G_loss: 0.0203\n",
      "Iteration [5600/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0002 | G_loss: 0.0182\n",
      "Iteration [5800/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0002 | G_loss: 0.0180\n",
      "Iteration [6000/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0003 | G_loss: 0.0200\n",
      "Iteration [6200/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0201\n",
      "Iteration [6400/10000] | D_real_loss: 0.0006 | D_fake_loss: 0.0002 | G_loss: 0.0131\n",
      "Iteration [6600/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0001 | G_loss: 0.0171\n",
      "Iteration [6800/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0001 | G_loss: 0.0177\n",
      "Iteration [7000/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0157\n",
      "Iteration [7200/10000] | D_real_loss: 0.0009 | D_fake_loss: 0.0001 | G_loss: 0.0204\n",
      "Iteration [7400/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0001 | G_loss: 0.0166\n",
      "Iteration [7600/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0004 | G_loss: 0.0192\n",
      "Iteration [7800/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0000 | G_loss: 0.0140\n",
      "Iteration [8000/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0004 | G_loss: 0.0177\n",
      "Iteration [8200/10000] | D_real_loss: 0.0004 | D_fake_loss: 0.0000 | G_loss: 0.0167\n",
      "Iteration [8400/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0000 | G_loss: 0.0138\n",
      "Iteration [8600/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0161\n",
      "Iteration [8800/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0165\n",
      "Iteration [9000/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0005 | G_loss: 0.0221\n",
      "Iteration [9200/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0001 | G_loss: 0.0181\n",
      "Iteration [9400/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0002 | G_loss: 0.0146\n",
      "Iteration [9600/10000] | D_real_loss: 0.0007 | D_fake_loss: 0.0001 | G_loss: 0.0214\n",
      "Iteration [9800/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0000 | G_loss: 0.0179\n",
      "Iteration [10000/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0000 | G_loss: 0.0174\n"
     ]
    }
   ],
   "source": [
    "from access_dict_by_dot import AccessDictByDot\n",
    "\n",
    "args = {\n",
    "              'image_size':32,\n",
    "              'g_conv_dim':32,\n",
    "              'd_conv_dim':64,\n",
    "              'noise_size':100,\n",
    "              'train_iters':10000,\n",
    "              'train_path': '/content/drive/MyDrive/Apple/',\n",
    "              \"test_path\": '/content/drive/MyDrive/emojis/Test_Apple',\n",
    "              'lr':0.001,\n",
    "              'beta1':0.5,\n",
    "              'beta2':0.999,\n",
    "              'batch_size':64,\n",
    "              'checkpoint_dir': '/content/drive/MyDrive/emojis/checkpoints',\n",
    "              'sample_dir': '/content/drive/MyDrive/emojis/samples',\n",
    "              'load': None,\n",
    "              'log_step':200,\n",
    "              'sample_every':1000,\n",
    "              'checkpoint_every':1000,\n",
    "              'spectral_norm': False,\n",
    "              'gradient_penalty': False,\n",
    "              'd_train_iters': 1\n",
    "}\n",
    "args = AccessDictByDot.load(args)\n",
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "0cEwOcQhCwEv",
    "outputId": "1f5facc1-9983-4011-edae-e644340edeb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models moved to GPU.\n",
      "Iteration [ 200/10000] | D_real_loss: 0.0049 | D_fake_loss: 0.0011 | G_loss: 0.0077\n",
      "Iteration [ 400/10000] | D_real_loss: 0.0004 | D_fake_loss: 0.0015 | G_loss: 0.0128\n",
      "Iteration [ 600/10000] | D_real_loss: 0.0010 | D_fake_loss: 0.0013 | G_loss: 0.0074\n",
      "Iteration [ 800/10000] | D_real_loss: 0.0022 | D_fake_loss: 0.0008 | G_loss: 0.0076\n",
      "Iteration [1000/10000] | D_real_loss: 0.0015 | D_fake_loss: 0.0003 | G_loss: 0.0144\n",
      "Iteration [1200/10000] | D_real_loss: 0.0005 | D_fake_loss: 0.0004 | G_loss: 0.0142\n",
      "Iteration [1400/10000] | D_real_loss: 0.0003 | D_fake_loss: 0.0002 | G_loss: 0.0160\n",
      "Iteration [1600/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0002 | G_loss: 0.0157\n",
      "Iteration [1800/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0002 | G_loss: 0.0163\n",
      "Iteration [2000/10000] | D_real_loss: 0.0004 | D_fake_loss: 0.0003 | G_loss: 0.0149\n",
      "Iteration [2200/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0002 | G_loss: 0.0187\n",
      "Iteration [2400/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0003 | G_loss: 0.0142\n",
      "Iteration [2600/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0002 | G_loss: 0.0171\n",
      "Iteration [2800/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0002 | G_loss: 0.0154\n",
      "Iteration [3000/10000] | D_real_loss: 0.0007 | D_fake_loss: 0.0004 | G_loss: 0.0131\n",
      "Iteration [3200/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0004 | G_loss: 0.0164\n",
      "Iteration [3400/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0000 | G_loss: 0.0158\n",
      "Iteration [3600/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0182\n",
      "Iteration [3800/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0161\n",
      "Iteration [4000/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0001 | G_loss: 0.0155\n",
      "Iteration [4200/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0000 | G_loss: 0.0165\n",
      "Iteration [4400/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0166\n",
      "Iteration [4600/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0001 | G_loss: 0.0172\n",
      "Iteration [4800/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0144\n",
      "Iteration [5000/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0000 | G_loss: 0.0153\n",
      "Iteration [5200/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0158\n",
      "Iteration [5400/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0004 | G_loss: 0.0174\n",
      "Iteration [5600/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0001 | G_loss: 0.0176\n",
      "Iteration [5800/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0000 | G_loss: 0.0158\n",
      "Iteration [6000/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0154\n",
      "Iteration [6200/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0157\n",
      "Iteration [6400/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0002 | G_loss: 0.0147\n",
      "Iteration [6600/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0002 | G_loss: 0.0159\n",
      "Iteration [6800/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0169\n",
      "Iteration [7000/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0171\n",
      "Iteration [7200/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0194\n",
      "Iteration [7400/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0170\n",
      "Iteration [7600/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0186\n",
      "Iteration [7800/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0157\n",
      "Iteration [8000/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0001 | G_loss: 0.0153\n",
      "Iteration [8200/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0135\n",
      "Iteration [8400/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0001 | G_loss: 0.0169\n",
      "Iteration [8600/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0172\n",
      "Iteration [8800/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0158\n",
      "Iteration [9000/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0001 | G_loss: 0.0144\n",
      "Iteration [9200/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0153\n",
      "Iteration [9400/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0167\n",
      "Iteration [9600/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0001 | G_loss: 0.0151\n",
      "Iteration [9800/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0160\n",
      "Iteration [10000/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0164\n"
     ]
    }
   ],
   "source": [
    "from access_dict_by_dot import AccessDictByDot\n",
    "\n",
    "args = {\n",
    "              'image_size':32,\n",
    "              'g_conv_dim':32,\n",
    "              'd_conv_dim':64,\n",
    "              'noise_size':100,\n",
    "              'train_iters':10000,\n",
    "              'train_path': '/content/drive/MyDrive/Apple/',\n",
    "              \"test_path\": '/content/drive/MyDrive/emojis/Test_Apple',\n",
    "              'lr':0.0005,\n",
    "              'beta1':0.5,\n",
    "              'beta2':0.999,\n",
    "              'batch_size':64,\n",
    "              'checkpoint_dir': '/content/drive/MyDrive/emojis/checkpoints',\n",
    "              'sample_dir': '/content/drive/MyDrive/emojis/samples',\n",
    "              'load': None,\n",
    "              'log_step':200,\n",
    "              'sample_every':1000,\n",
    "              'checkpoint_every':1000,\n",
    "              'spectral_norm': False,\n",
    "              'gradient_penalty': False,\n",
    "              'd_train_iters': 2\n",
    "}\n",
    "args = AccessDictByDot.load(args)\n",
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Be4oRjZbCwIL",
    "outputId": "6387e412-c82f-45ea-e692-b06a54120ac7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models moved to GPU.\n",
      "Iteration [ 200/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0005 | G_loss: 0.0144\n",
      "Iteration [ 400/10000] | D_real_loss: 0.0006 | D_fake_loss: 0.0005 | G_loss: 0.0122\n",
      "Iteration [ 600/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0002 | G_loss: 0.0147\n",
      "Iteration [ 800/10000] | D_real_loss: 0.0018 | D_fake_loss: 0.0023 | G_loss: 0.0069\n",
      "Iteration [1000/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0003 | G_loss: 0.0131\n",
      "Iteration [1200/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0002 | G_loss: 0.0153\n",
      "Iteration [1400/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0001 | G_loss: 0.0157\n",
      "Iteration [1600/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0003 | G_loss: 0.0172\n",
      "Iteration [1800/10000] | D_real_loss: 0.0005 | D_fake_loss: 0.0022 | G_loss: 0.0054\n",
      "Iteration [2000/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0002 | G_loss: 0.0164\n",
      "Iteration [2200/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0001 | G_loss: 0.0170\n",
      "Iteration [2400/10000] | D_real_loss: 0.0001 | D_fake_loss: 0.0003 | G_loss: 0.0135\n",
      "Iteration [2600/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0001 | G_loss: 0.0161\n",
      "Iteration [2800/10000] | D_real_loss: 0.0002 | D_fake_loss: 0.0006 | G_loss: 0.0133\n",
      "Iteration [3000/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0001 | G_loss: 0.0150\n",
      "Iteration [3200/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0001 | G_loss: 0.0175\n",
      "Iteration [3400/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0001 | G_loss: 0.0156\n",
      "Iteration [3600/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0001 | G_loss: 0.0159\n",
      "Iteration [3800/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0001 | G_loss: 0.0162\n",
      "Iteration [4000/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0001 | G_loss: 0.0163\n",
      "Iteration [4200/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0172\n",
      "Iteration [4400/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0001 | G_loss: 0.0156\n",
      "Iteration [4600/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0001 | G_loss: 0.0166\n",
      "Iteration [4800/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0001 | G_loss: 0.0156\n",
      "Iteration [5000/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0162\n",
      "Iteration [5200/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0001 | G_loss: 0.0153\n",
      "Iteration [5400/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0142\n",
      "Iteration [5600/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0151\n",
      "Iteration [5800/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0149\n",
      "Iteration [6000/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0141\n",
      "Iteration [6200/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0155\n",
      "Iteration [6400/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0156\n",
      "Iteration [6600/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0155\n",
      "Iteration [6800/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0145\n",
      "Iteration [7000/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0152\n",
      "Iteration [7200/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0162\n",
      "Iteration [7400/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0155\n",
      "Iteration [7600/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0166\n",
      "Iteration [7800/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0154\n",
      "Iteration [8000/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0164\n",
      "Iteration [8200/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0155\n",
      "Iteration [8400/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0161\n",
      "Iteration [8600/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0155\n",
      "Iteration [8800/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0155\n",
      "Iteration [9000/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0137\n",
      "Iteration [9200/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0151\n",
      "Iteration [9400/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0180\n",
      "Iteration [9600/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0155\n",
      "Iteration [9800/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0157\n",
      "Iteration [10000/10000] | D_real_loss: 0.0000 | D_fake_loss: 0.0000 | G_loss: 0.0153\n"
     ]
    }
   ],
   "source": [
    "from access_dict_by_dot import AccessDictByDot\n",
    "\n",
    "args = {\n",
    "              'image_size':32,\n",
    "              'g_conv_dim':32,\n",
    "              'd_conv_dim':64,\n",
    "              'noise_size':100,\n",
    "              'train_iters':10000,\n",
    "              'train_path': '/content/drive/MyDrive/Apple/',\n",
    "              \"test_path\": '/content/drive/MyDrive/emojis/Test_Apple',\n",
    "              'lr':0.0005,\n",
    "              'beta1':0.5,\n",
    "              'beta2':0.999,\n",
    "              'batch_size':64,\n",
    "              'checkpoint_dir': '/content/drive/MyDrive/emojis/checkpoints',\n",
    "              'sample_dir': '/content/drive/MyDrive/emojis/samples',\n",
    "              'load': None,\n",
    "              'log_step':200,\n",
    "              'sample_every':1000,\n",
    "              'checkpoint_every':1000,\n",
    "              'spectral_norm': False,\n",
    "              'gradient_penalty': False,\n",
    "              'd_train_iters': 4\n",
    "}\n",
    "args = AccessDictByDot.load(args)\n",
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_hHByecDQZR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
